Memory Virtualization
![[Pasted image 20230316174050.png]]

No way we can save all these data
we want to leaveit in the memory at wherever it was

![[Pasted image 20230316174312.png]]

Process B need to use some memory
like what process A is doing

we know that we can save registers
we have other gpr

we can add more registers

![[Pasted image 20230316174519.png]]
How many register do you need?
- Size of
- Starting Address (Base Address)

right now process A is running
Process A address = Physical address
how to build this process A address?

![[Pasted image 20230316174921.png]]
Process and V Address (virtual address)
virtuall address is what you see on the app (that's given)
what you need to figure out is where is it in memory you need to go 
(what cell in the memory you are at)


you need to add the register
size is something new that we have not used yet
**the size is just used to give you exception when you run your code**
if the address you're using is bigger than your size, then exception will occur

how can you can share physical memory between multiple processes?
-> mmap -> map physical memory into your process, and you have full control

level 1 -> level 2 -> level 3
what's expected for the seminar:
- you need to decide where you have a free size
- you would need to be able to tell me whic secton is still free
- FREE MEMORY MANAGEMENT FUNCTION
- if will be required for us to use linked list, array is not acceptable 


# LEVEL 3

Segments
-> Block of Memory
-> normal proceses are using segments
-> why is that? if we use full blocks, we might not need all the memory(it is hard to find the space for another process)
-> it make sense if we can reduce the space
-> the way we do that is by splitting this memory into segments
-> process memory segments:
	-> where is this process stored
	-> need to know what happen with those
	-> **automated memory allocation** that was done by the CPU (STACK)
	-> **Dynamic memory allocation** (HEAP)
	-> Text
	-> Data
![[Pasted image 20230316180309.png]]
The CPU does not have enough time to wait for the data from the Hard Drives

![[Pasted image 20230316180528.png]]
most of the memory are usually between heap and stack
they're fixed (text and data)
Heap and Stack is the larger one, and they're keep going

the label (tells you where it grows)
Stack is "stacking", so it is growing up
Heap is growing down (so the middle area is free)

how do we handle switching of these two processes?
![[Pasted image 20230316180727.png]]

CPU is trying to switch between these two processes
Let's look at the pysical memory:
(NOT TO SCALE)
![[Pasted image 20230316181002.png]]
size and location of each segments
since it is not that much yet, we can use the registers
how many registers do we need for the size? 4 registers for the size and 4 registers for the place adress (location)

![[Pasted image 20230316181343.png]]

contact switch
all the orange will switch to green and process B will be able to run
![[Pasted image 20230316181447.png]]
![[Pasted image 20230316181543.png]]

Example:
![[Pasted image 20230316181733.png]]

![[Pasted image 20230316182016.png]]

map some pages
could use that map

l1 cache memory, and you want to allocate that between the 32 k to 34 k

SWAP is the other way around
its much slower than your memory
pagesys 

large file that get sits at the hard drive, and will be used when this get filled up
its a workaround for the operating system when they're in trouble

"timestamp" when they're executed last, figure it out, and move its data to its memory
actually per page
it's a partition on linux 
file on windows

memory is never fractional
its always an integer

![[Pasted image 20230316183328.png]]

as long you can determine in the end, where is the location is at, then you're good

![[Pasted image 20230316184051.png]]
Translation table
we only care about segments

# lecture 9 - 03212023

![[Pasted image 20230321174353.png]]
Split these areas in smaller chunks
we only allocate memory for what's needed

the size that's most common right now -> page size about 4KByte
2^32 is 4 gb

![[Pasted image 20230321175004.png]]

you will play in sequences of 4 bits
(NIBBLE)
![[Pasted image 20230321175150.png]]


each section on the page have 4 kb
![[Pasted image 20230321175415.png]]

![[Pasted image 20230321175554.png]]

![[Pasted image 20230321175826.png]]
+400 is the "same" region of the memory

"an offset from where the page starts"
this two location are both have the same offset, but located at different page
you have 4k different offset
how many bits you need to encode 4k numbers
12 BITS (2^12) needed to encode the 4k numbers

**within this address, we can reserve the last 12 bits just for the offset**
if you make any number modulo 4k, you will get those offsets
reserve 12 bits for offsets
![[Pasted image 20230321180130.png]]
we reserve 4kb per process
then the 20 bits that are left could be used for page numbers

2^20 is one meg of numbers (if each number will be one byte, then you can call it megabyte)
(one mega pages) -> 1,000,000 pages (each number will move to the pages)

map this pages within the physical memory
**Coherent Memory allocation**

**Memory management library** 
DMA Transfer -> Direct Memory Access
in DMA, the CPU does not involve in the memory access
different piece of hardware that you add to the system
the hardware piece is called memory management hardware
"adhered to the page"

it make sense that the program will not have access to the page that have data

![[Pasted image 20230321181301.png]]
different function of memory allocation
stack, malloc, etc that the process will see, that shows up on the right side
this mapping from right side to the left side is the subject for this class (memory mapping)

![[Pasted image 20230321181437.png]]
memory allocation library will decide that it maps that page on the right to the lpage on the left (yellow - yellow, green - green)

keep track of that process with structures that keep details inside of it
the priority, open files, bunch of different structure memorys
flag in there called status
move it to the queue reserve, to ready to run

when you run your process, this number is given:
![[Pasted image 20230321181742.png]]
you need to find a way to keep track of those arrows (mapping to the physical memory)

Cheating method:
"array of addresses"

these are not pointers, these are indicies 
![[Pasted image 20230321182048.png]]
reserve a bit here just to know if the bit is valid or not
![[Pasted image 20230321182125.png]]

if its empty, then there's nothing there
![[Pasted image 20230321182154.png]]
page 1 is mapped to the page 5
![[Pasted image 20230321182221.png]]
each time you create a process, you allocate the huge table (1 meg records, timeshow big of the record (a number and flags) 4 MB)

20 bits for the page number
"letting the operating system know if the mapping is valid or not"
if you need 

dirty bits
once you modify a location within that page, you need to let the os know that there's something there, esp in swapping

swapping -> take things from the physical memory, then move it to the slower memory to make space on the physical memory.

![[Pasted image 20230321182629.png]]

process A virtual address first, and we try to find the physical memory address

bit manipulation
2^10 in binary

in binary there's 1 in the least significant bit (2^0)
you shifted that 1 to the left (one unit)
on the second location, bit to the index 1, there's your 1
![[Pasted image 20230321183320.png]]
moving left (or multiplying by 2) in binary
![[Pasted image 20230321183522.png]]
bitshift
![[Pasted image 20230321183707.png]]
4k will barely move in page 1
if we look at the bit allingment, we can hide the 3 and use it as an offset
![[Pasted image 20230321183757.png]]
everything else here will gives us the page number
![[Pasted image 20230321183815.png]]
the last line: offset is zero, page is one
![[Pasted image 20230321184016.png]]

![[Pasted image 20230321184131.png]]
use the page number as the index in the table on the middle
![[Pasted image 20230321184311.png]]
shifted left by 12 units
and fill it with zeros (to make room for the offsets)

we get the physical address by going through the page table
for each process
4 mb in this implementation that tis OS need to keep track of

# LECTURE 10 - 022323

![[Pasted image 20230323174346.png]]
you need full long table because you have a lot of pages
mapping between the virtual index table, and the physical page number

index inside the array, then the value inside the array that we pushed back
ofset is for the "column on the VA"

![[Pasted image 20230323175618.png]]

shift right to get the page number, how do you get the offset?
![[Pasted image 20230323175824.png]]

by using masking
if your page table is only one bit, then you use a different masking 
if your pages is 10 kb, then the mask will be 0x03FF

1 meg of records * 4 records = 4 mb
we save the physical memory, but now we added someting that's still inconvinience
usually we only several pages, you ended up only using sevaral pages out of that 4 mb

at that point, you try to find a solution and you realized that you already have solution
why don't you jus tuse pages?
i meg of record, can hold more indicies on that array page table

4kb as the size of one page, one records is 1 byte, so you have 1 k record
1 pages, and now you keep track of that
reserve the bits to keep of which of this records are valid

to find the records within the table, you will need 10 bits
12 bits to address everything inside the page
make a reasoning for directories

![[Pasted image 20230323181225.png]]

split this section in 2, one section to locate a specific records
everything else now should give you the information about the page that you need to use. 

split this per pages (memory pages) with pages table record
![[Pasted image 20230323181457.png]]
1k record can fit into one pages, so instead of 1m records, we only have 1k, and it stays inside one page

what happens on the other record, they're on different pages
10 bits to find the records
"offset within the table", everything else will give you the page number
splitting the large memory section into pages
if the page number straight to the physical memory?

you need a mapping for that too (much smaller table with mapping between those addresses and where that frame or that page is within the physical memory)

count how many pages you use for your records
the flags are part of the records themselves, not the part of the virtual memory
everyhing endded up as your address
"you're encrypting something"

![[Pasted image 20230323182207.png]]
this will map your record inside one pages
and the next one will map your pages
![[Pasted image 20230323182401.png]]
first implementation, inside the green space, you have everything there
(table of records)
![[Pasted image 20230323182432.png]]

![[Pasted image 20230323182510.png]]
the 7th
![[Pasted image 20230323182524.png]]
virtual 5, physical 12


![[Pasted image 20230323182633.png]]
offset within the page -> 2 (the second one)
![[Pasted image 20230323182652.png]]
now you're asking which page? now you show 1
![[Pasted image 20230323182709.png]]
if you write 1 there, you will give user access to the real page number
![[Pasted image 20230323182849.png]]
index of that one, (index within this new table)
![[Pasted image 20230323182913.png]]
which records within these table?
![[Pasted image 20230323183025.png]]
"part of the page table (owned by the operating system)"
directory of records (probably random number tables)
one directory per process

1k pages for the 32 bits system, then if the page is too much, then you do more directories of directories

define the table at kernel level

this translation/conversion from the va to pa, it needs to happen if you need to access something in the memory

instruction sets is to move address in the memory, 
load word (lw) probabbly will need to access this

memory access can be slow for the processor at this point, so you need to add hardware functionality to help this

implement this mapping in that piece of hardware, and memory need to be free, so that hardware can see the mapping

second option is having a caching thing, so mapped in the hardware, but in programming, most of this record is "usually close to each other" maybe element in the array will be close to each other. the first access to that array will be very slow, but all the next whatever to fill that 4k, will be fairly fast

harware will have the limit, depend on the how you arrange it 
MMU, memory management UNIT
all this table is a lookup table
even PNG also a lookup table


# Lecture 11 - 04112023
MMU is memory management unit

sparse matrices -> most of the element is zero
keep few record
if you just need to keep a few record, you need to save it

virtual page number
hardware part -> needs to save the index itself

the record is already in the mmu
the page missed(is not in the MMU)
the record itself is not in the hardware
you have to go through the slow process of accessing the memory to 

regular if accessing the memory
miss 
hit in the cache


## The intent for this seminar

## FREE MEMORY MANAGEMENT
use list for this
that keep track for the free spaces
when you start, all the memory are available

![[Pasted image 20230404175623.png]]

![[Pasted image 20230404175714.png]]
![[Pasted image 20230404175901.png]]

![[Pasted image 20230404180020.png]]
![[Pasted image 20230404180236.png]]

![[Pasted image 20230404180546.png]]


somehow we got a memory from this block?
![[Pasted image 20230404181044.png]]

lets say if we have a process that need 10k, we can choose a process that have lower memory left (the 20k), so it can stay there, instead of dividing the bigger memory again

flag is bitfield using the old 