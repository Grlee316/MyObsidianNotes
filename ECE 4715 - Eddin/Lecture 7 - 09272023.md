Transformation Pipelines
pipeline
make_pipeline

pipeline is like a workflow
pipeline will have several items:
-> Simple imputer (inputing the median data to the empty areas)

pipeline typically expects transformers
pipeline is accessible like every other lists
standard scaler

categorical data -> one hot encoding

simple imputer -> function transformer -> scaler 

take a numerical data -> create a function -> scale -> give an output

use transformer to combine all of them
skipping using the passtrhough

x' -> goes to the box and preprocess it
every sample after the preprocessing make it easier to run

linear regression -> 
3 dimensional surface (hyperplane / hypersurface)
predict will be the last step
model does not transform data, it predicts
input -> preprocesser -> fit to the second one -> output
linear regression is the big pipeline, it generated a different y

RMSE -> just bring it back to the error, instead of the error squared
the data is underfitted
if the preprocessing is bad, everything else will be bad
we don't want to overfitted as well

test set should not be a part of the learning model
you don't want to fit the test
you can always do split the training test
80 - 20
70 - 30
